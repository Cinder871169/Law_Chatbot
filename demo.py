import os
import json
import glob
import streamlit as st
from dotenv import load_dotenv

# Import cÃ¡c thÃ nh pháº§n RAG vÃ  Chat
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from langchain_community.document_loaders import (
    DirectoryLoader,
    PyPDFLoader,
    Docx2txtLoader,
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.retrievers import BM25Retriever
from langchain_classic.retrievers import EnsembleRetriever
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

# --- 1. Cáº¤U HÃŒNH LÆ¯U TRá»® ---
HISTORY_DIR = "chat_histories"
if not os.path.exists(HISTORY_DIR):
    os.makedirs(HISTORY_DIR)


def save_chat(title, messages):
    safe_title = "".join([c for c in title if c.isalnum() or c in (" ", "_")]).rstrip()
    file_path = os.path.join(HISTORY_DIR, f"{safe_title}.json")
    data = [
        {
            "role": "user" if isinstance(m, HumanMessage) else "assistant",
            "content": m.content,
        }
        for m in messages
    ]
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)


def load_chat(title):
    file_path = os.path.join(HISTORY_DIR, f"{title}.json")
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return [
                (
                    HumanMessage(content=m["content"])
                    if m["role"] == "user"
                    else AIMessage(content=m["content"])
                )
                for m in data
            ]
    return []


def delete_chat(title):
    file_path = os.path.join(HISTORY_DIR, f"{title}.json")
    if os.path.exists(file_path):
        os.remove(file_path)


# --- 2. Há»† THá»NG RAG HYBRID ---
@st.cache_resource
def init_rag():
    loader_pdf = DirectoryLoader("data", glob="**/*.pdf", loader_cls=PyPDFLoader)
    loader_docx = DirectoryLoader("data", glob="**/*.docx", loader_cls=Docx2txtLoader)
    documents = loader_pdf.load() + loader_docx.load()

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, chunk_overlap=200, separators=["\n\n", "\n", ". ", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)

    embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
    vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)

    vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    keyword_retriever = BM25Retriever.from_documents(chunks)
    keyword_retriever.k = 3

    return EnsembleRetriever(
        retrievers=[keyword_retriever, vector_retriever], weights=[0.5, 0.5]
    )


# --- 3. GIAO DIá»†N CHÃNH ---
st.set_page_config(page_title="Luáº­t sÆ° áº£o Gemini", layout="wide")
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.3)

if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_chat_title" not in st.session_state:
    st.session_state.current_chat_title = None

# Sidebar quáº£n lÃ½ danh sÃ¡ch chat
with st.sidebar:
    st.title("ğŸ“œ Lá»‹ch sá»­ chá»§ Ä‘á»")
    if st.button("â• Äoáº¡n chat má»›i", use_container_width=True):
        st.session_state.current_chat_title = None
        st.session_state.messages = []
        st.rerun()

    st.divider()
    existing_chats = [
        os.path.basename(f).replace(".json", "")
        for f in glob.glob(f"{HISTORY_DIR}/*.json")
    ]

    for title in sorted(existing_chats, reverse=True):
        cols = st.columns([0.8, 0.2])
        # NÃºt chá»n chat
        if cols[0].button(f"ğŸ“„ {title}", key=f"sel_{title}", use_container_width=True):
            st.session_state.current_chat_title = title
            st.session_state.messages = load_chat(title)
            st.rerun()
        # NÃºt xÃ³a chat
        if cols[1].button("ğŸ—‘ï¸", key=f"del_{title}"):
            delete_chat(title)
            if st.session_state.current_chat_title == title:
                st.session_state.current_chat_title = None
                st.session_state.messages = []
            st.rerun()

# --- 4. Xá»¬ LÃ LOGIC CHAT ---
display_title = (
    st.session_state.current_chat_title
    if st.session_state.current_chat_title
    else "Cuá»™c há»™i thoáº¡i má»›i"
)
st.title(f"âš–ï¸ {display_title}")

retriever = init_rag()
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Báº¡n lÃ  Luáº­t sÆ° áº£o chuyÃªn nghiá»‡p. DÃ¹ng ngá»¯ cáº£nh: {context}. TrÃ­ch dáº«n Äiá»u/Khoáº£n rÃµ rÃ ng.",
        ),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
    ]
)

rag_chain = (
    RunnablePassthrough.assign(
        context=lambda x: "\n\n".join(
            d.page_content for d in retriever.invoke(x["input"])
        )
    )
    | prompt
    | llm
    | StrOutputParser()
)

# Hiá»ƒn thá»‹ lá»‹ch sá»­ tin nháº¯n
for msg in st.session_state.messages:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    st.chat_message(role).write(msg.content)

# Nháº­p liá»‡u tá»« ngÆ°á»i dÃ¹ng
if user_input := st.chat_input("Há»i vá» phÃ¡p luáº­t..."):
    # BÆ¯á»šC 1: Náº¿u chÆ°a cÃ³ tiÃªu Ä‘á», táº¡o tiÃªu Ä‘á» trÆ°á»›c
    if st.session_state.current_chat_title is None:
        with st.spinner("Äang khá»Ÿi táº¡o chá»§ Ä‘á»..."):
            title_gen_prompt = (
                f"TÃ³m táº¯t cÃ¢u há»i sau thÃ nh tiÃªu Ä‘á» cá»±c ngáº¯n (dÆ°á»›i 5 tá»«): {user_input}"
            )
            new_title = llm.invoke(title_gen_prompt).content.strip().replace('"', "")
            st.session_state.current_chat_title = new_title

    # BÆ¯á»šC 2: ThÃªm tin nháº¯n ngÆ°á»i dÃ¹ng vÃ o bá»™ nhá»› vÃ  hiá»ƒn thá»‹
    st.session_state.messages.append(HumanMessage(content=user_input))
    st.chat_message("user").write(user_input)

    # BÆ¯á»šC 3: Tráº£ lá»i cÃ¢u há»i ngay láº­p tá»©c
    with st.chat_message("assistant"):
        with st.spinner("Äang tra cá»©u luáº­t..."):
            response = rag_chain.invoke(
                {
                    "input": user_input,
                    "chat_history": st.session_state.messages[:-1][
                        -10:
                    ],  # Láº¥y lá»‹ch sá»­ trÆ°á»›c Ä‘Ã³
                }
            )
            st.write(response)
            st.session_state.messages.append(AIMessage(content=response))

            # BÆ¯á»šC 4: LÆ°u vÃ o file
            save_chat(st.session_state.current_chat_title, st.session_state.messages)

            # Rerun Ä‘á»ƒ tiÃªu Ä‘á» trÃªn cÃ¹ng cáº­p nháº­t theo chá»§ Ä‘á» má»›i táº¡o
            st.rerun()
