import os
from dotenv import load_dotenv
from langchain_community.document_loaders import (
    DirectoryLoader,
    Docx2txtLoader,
    PyPDFLoader,
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma

load_dotenv()


def ingest_data():
    print("ğŸš€ Äang khá»Ÿi Ä‘á»™ng quy trÃ¬nh náº¡p dá»¯ liá»‡u tá»‘i Æ°u...")

    # 1. Load tÃ i liá»‡u
    loader_docx = DirectoryLoader("data", glob="**/*.docx", loader_cls=Docx2txtLoader)
    loader_pdf = DirectoryLoader("data", glob="**/*.pdf", loader_cls=PyPDFLoader)
    documents = loader_docx.load() + loader_pdf.load()

    # 2. Chia nhá» vÄƒn báº£n (Sá»­ dá»¥ng thÃ´ng sá»‘ tá»‘i Æ°u tá»« notebook)
    # Cáº¯t theo thá»© tá»±: Äoáº¡n vÄƒn -> DÃ²ng -> CÃ¢u -> Tá»« Ä‘á»ƒ giá»¯ nguyÃªn Ã½ nghÄ©a phÃ¡p lÃ½
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800, chunk_overlap=100, separators=["\n\n", "\n", ". ", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… ÄÃ£ táº¡o {len(chunks)} Ä‘oáº¡n vÄƒn báº£n.")

    # 3. Táº¡o Vector Database (ChromaDB)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
    Chroma.from_documents(
        documents=chunks, embedding=embeddings, persist_directory="chroma_db_luat_new"
    )
    print("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o ChromaDB.")


if __name__ == "__main__":
    ingest_data()
